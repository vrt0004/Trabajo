\capitulo{3}{Conceptos teóricos}

\section{Introducción}

Todo el software que se ejecuta en las computadoras se escribe en un algún lenguaje de programación,  pero antes de poder ejecutar el programa, primero debe transformarse a un formato en el que la computadora pueda ejecutarlo.  

Un \textit{compilador} es un programa que lee  un programa  (\textit{programa fuente}) escrito en un lenguaje (\textit{lenguaje fuente}), y lo traduce a un programa equivalente (\textit{programa objeto})  en otro lenguaje (\textit{lenguaje objeto}).

El proceso de compilación se puede dividir en varias etapas: \textit{ANÁLISIS} (\textit{front end} o \textit{etapa inicial}), \textit{generación de código intermedio} (\textit{middle end})  y \textit{SÍNTESIS} (\textit{back end} o \textit{etapa final}).  La etapa de \textit{ANÁLISIS} divide el programa fuente en componentes e impone una estructura gramatical sobre ellas. También recoge información sobre el programa fuente que se almacena en una estructura de datos llamada \textit{tabla de símbolos}. Después se utiliza esta estructura gramatical para crear una representación intermedia del programa fuente. La etapa de \textit{SÍNTESIS}  construye el programa destino a partir de la representación intermedia y de la información de la \textit{tabla de símbolos}\cite{jimenez2009compiladores}\cite{sintactico}.


\imagen{compilador}{Estructura de un compilador \cite{apuntes}.} 

La etapa de \textit{ANÁLISIS} agrupa aquellas fases que dependen principalmente del lenguaje fuente y comprende:

\begin{itemize}
	\item El \textbf{analizador léxico} (\textit{scanner}) que agrupa los caracteres individuales en entidades lógicas.
	\item El \textbf{analizador sintáctico} (\textit{parser}), que trataremos con más detalle a continuación, analiza la estructura general de todo el programa, agrupando las entidades simples identificadas por el \textit{scanner} en construcciones mayores como sentencias, bucles, rutinas, que componen el programa complejo. Normalmente se utiliza la representación de \textit{árboles sintácticos} para reflejar dicha estructura.
	\item El \textbf{analizador semántico} utiliza los \textit{árboles sintácticos} y la información de la \textit{tabla de símbolos} para comprobar la consistencia semántica del programa. También recopila información sobre el tipo (qué variables almacenan enteros, cuáles número en coma flotante,\dots{}).
	
\end{itemize}

La etapa de \textit{SÍNTESIS} agrupa aquellas fases que dependen principalmente de la máquina objetivo y comprende:	

\begin{itemize}

\item El \textbf{optimizador de código intermedio}, que transforma la representación intermedia en otra equivalente pero más eficiente.
\item El \textbf{generador de código}, que genera un programa equivalente para su ejecución en la máquina objetivo,  añadiéndole posiblemente rutinas de biblioteca y código de inicialización.
\item Puede haber un \textbf{optimizador }de código para mejorar aún más el código generado.

\end{itemize}


\section{Análisis sintáctico}

El análisis sintáctico (\textit{parser}) es la fase del procesador de lenguaje que toma como entrada los componentes léxicos (\textit{tokens}) que le envía el analizador léxico y comprueba si con ellos se puede formar alguna sentencia válida del lenguaje. 

La sintaxis de los lenguajes de programación habitualmente se describe mediante gramáticas libres de contexto (o gramáticas tipo 2).

Estas gramáticas están formadas por:
\begin{itemize}
	\item Un conjunto finito y no vacío de símbolos terminales(o tokens):  $\Sigma$.
	\item Un conjunto de símbolos no terminales:  $N$.
	\item  Un símbolo especial llamado axioma o símbolo inicial $S$ $\in N$.
	\item Un conjunto de producciones que relacionan los símbolos terminales con los no terminales, de la forma:
$ X\rightarrow w$ con $X$ $\in N$ y $w$ $\in(\Sigma\cup N)^{*}$.

\end{itemize}

%
%\subsection{Producción}
%Una producción o regla de re-escritura es un par ordenado de cadenas sobre un alfabeto((x,y):x,y$ \in\Sigma^{\ast}$). Se representa por $x\rightarrow y$. x es la parte izquierda o antecedente de la producción e y es la parte derecha o consecuente.

Para verificar si una instrucción pertenece al lenguaje, se construye el árbol sintáctico de la instrucción a partir de los \textit{tokens} recibidos y que constituirán las hojas del árbol sintáctico. 

%Si el analizador sintáctico no puede formar una sentencia produce un mensaje de error, tratando de indicar las causas por las cuales no puede formar la sentencia. 

Para realizar el análisis es necesario calcular previamente tres tipos de conjuntos: anulables, iniciales (\textit{FIRST}) y seguidores (\textit{FOLLOW}). Los anulables son los no terminales que pueden generar la palabra vacía ($\epsilon$). El conjunto \textit{FIRST}($\alpha$) de una cadena es el conjunto de terminales que pueden comenzar cualquier cadena obtenida a partir de $\alpha$ y el conjunto \textit{FOLLOW}(\textit{A}) de un no terminal es el conjunto de terminales que pueden aparecer inmediatamente después del \textit{A}. Si \textit{A} es el último símbolo entonces se incluye el separador \$. 

Para las gramáticas libres de contexto existen dos tipos básicos de analizadores sintácticos: los descendentes (\textit{top-down}) y los ascendentes (\textit{bottom-up}). Los descendentes construyen el árbol comenzando por la raíz y bajan hasta las hojas y los ascendentes construyen el árbol desde las hojas hasta la raíz.

%\section{Conceptos previos}

%

%\section{Gramática}
%El estudio de los lenguajes se puede hacer desde tres puntos de vista:
%\begin{itemize}
%	\item El de la interpretación: tiene que ver con la semántica de los lenguajes intenta formalizar el significado de las sentencias de un lenguaje.
	
%	\item La generación de lenguajes: consiste en encontrar los mecanismos que permitan enumerar las cadenas que pertenecen a un lenguaje. Estos mecanismo son las gramáticas.
	
%	\item El del reconocimiento del lenguaje: esta muy ligado a la teoría de autómatas y es << ... el estudio de algoritmos o estructuras de máquinas que permiten, dado un lenguaje L y una cadena x, determinar si $ x\in L$ o  $x\not\in L$ >>. \footnote{ Fernández,1995} 
	
	
%\end{itemize}


%\subsection{Derivación directa}
%Sea $x\rightarrow y$ una producción y $v,w\in\Sigma^{*}$. Se dice que w deriva directamente de v y se escribe $v\Rightarrow w$ si y sólo si existen $z,u\in\Sigma^{*}$ tales que $v=zxu$, $w=zyu$ y $x\rightarrow y$. 
%\subsection{Derivación (En uno o más pasos)}
%
%w deriva de v y se escribe $v\Rightarrow^{+}w$ cuando existen $u_{0},u_{1},...,u_{n}\in\Sigma^{*}$ tales que:
%$v=u_{0}$
%$u_{0}\Rightarrow u_{1}$
%$u_{1}\Rightarrow u_{2}$
%$\vdots$
%$u_{n-1}\Rightarrow u_{n}$
%$u_{n1}=w$
%
%A la secuencia $u_{0},u_{1},...,u_{n}$ se la llama cadena de derivación de longitud n.
%
%
%En el contexto de las gramáticas el alfabeto ca a estar formado por la unión de los alfabetos de terminales y no terminales.Ademas el antecedente de una producción nunca va a poder ser epsilon y ha de contener al menos un no terminal. 
%
%\subsection{Derivación más a la izquierda}
%Cuando las producciones utilizadas en la derivación se aplican siempre a los símbolos más a la izquierda.
%
%\subsection{Derivación más a la derecha}
%Cuando las producciones se aplican a los símbolos más a la derecha.
%\subsection{Forma sentencial}
%Dada una gramática $(\Sigma,N,P,S)$. una cadena $\alpha\in(\Sigma\cup N)*$ es una forma sentencial de esa gramática si existe una derivación que produce $\alpha$ a partir del axioma S, es decir si $S\Rightarrow*a$.
%\subsection{Frase o sentencia}
%Es una forma sentencial $\alpha$ que solo contiene símbolos terminales($\alpha\in\Sigma* $).
%\subsection{Lenguaje generado por una gramática}
%El lenguaje generado por una gramática G se representa por L(G) y se define como el conjunto de todas las sentencias de la gramática G. 
%$L(G)={x\in\Sigma*:S\Rightarrow ^{+} x}$
%\subsection{Gramáticas equivalentes}
%Se dice que dos gramáticas son equivalentes si generan el mismo lenguaje $L(G{\small 1})=L(G{\small 2})$.
%Se representa por $G{\small 1}\equiv G{\small 2}$
%\subsection{Gramáticas recursiva en un cierto símbolo no terminal U}
%Cuando existe una forma sentencial de U que contiene a U.
%$U\Rightarrow^{+}xUy con x,y\in(\Sigma\cup N)^{*}$
%La gramática será recursiva si es recursiva para algún no terminal.
%\begin{itemize}
%	\item Si $x=\varepsilon$ se dice que es una gramática recursiva a izquierdas.
%	\item Si $y=\varepsilon$ se dice que es una gramática recursiva a derechas.
%\end{itemize}
%


%\section{Clasificación de las gramáticas}
%\subsection{Gramáticas de tipo 0}
%
%Las gramáticas de tipo 0 o gramáticas de Chomsky, con reglas de producción de la forma:
%$u\rightarrow v con u=xAy \in (\Sigma\cup N)^{+}\wedge A\in N\wedge x,y,v \in(\Sigma\cup N)^{*}$
%El conjunto de lenguajes de tipo 0 coincide con el de todos los lenguajes gramaticales posibles.
%Puede demostrarse que todo lenguaje generado por una gramática de Chomsky puede generarse también por unas gramáticas más restrictivas llamadas gramáticas con estructura de frase, cuyas reglas de producción son de la forma:
%$xAy \rightarrow xvy con x,y,v\in(\Sigma\cup N)^{*}\wedge A\in N$
%\subsection{Gramáticas de tipo 1}
%
%Tambien llamadas sensibles al contexto, con reglas de producción de la forma:
%$xAy \rightarrow xvy con x,y\in(\Sigma\cup N)^{*}\wedge A\in N\wedge v\in(\Sigma\cup N)^{+}$
%En los lenguajes generados por estas gramáticas el significado de las "palabras" depende de su posición en la frase.
%A la x e y ses a lo que se le llama contexto( es decir, A sólo puede transformarse en v si va precedido de x y al mismo tiempo seguido de y).
%No tiene reglas compresoras, aunque se tolera la regla $S\rightarrow\varepsilon\varepsilon$.
%Son las gramáticas de mayor categoría que se suelen utilizar (la mayor parte de los lenguajes de ordenador pertenece a este grupo, aunque gran parte de las reglas de las gramáticas que los generan pueden reducirse  a las de tipo 2).
%Se caracteriza por que la longitud de las formas sentenciales partiendo de S es siempre no decreciente.
%
%\subsection{Gramáticas de tipo 2}
%También conocidas como gramáticas independientes del contexto tienen reglas de la forma:
%$A\rightarrow v con A\in N\wedge v\in(\Sigma\cup N)^{*}$
%Se vuelven a introducir leyes compresoras, pero es fácil demostrar que se puede obtener una gramática equivalente que no las tenga, obteniéndose una definición algo mas restrictiva:
%$A\rightarrow v con A \in N\wedge v\in(\Sigma\cup N)^{+}$
%además es posible que se tenga la regla $S\rightarrow\varepsilon$
%En los lenguajes generados por las gramáticas de este tipo el significado de las «palabras»  es independiente de su posición.
%Una última característica de este tipo de gramáticas es que las derivaciones obtenidas al utilizarlas se pueden representar utilizando árboles.
%\subsection{Gramáticas de tipo 3}
%También conocidas como gramáticas regulares, tienen reglas de la forma:
%$A\rightarrow aB \wedge A\rightarrow b o de la formaA\rightarrow Ba \wedge A\rightarrow b con A,B\in N \wedge a,b\in \Sigma $
%
%A las gramáticas regulares del primer tipo se las llama gramáticas regulares a derechas, a las del segundo tipo gramáticas regulares a izquierdas, en realidad son totalmente equivalentes. Si $\varepsilon$ pertenece al lenguaje , se tolera la regla $S\rightarrow\varepsilon$
%
%Existe una generalización de este tipo de gramáticas llamadas gramáticas lineales con reglas de la forma:
%
%$A\rightarrow w B \wedge A\rightarrow v o de la forma A\rightarrow Bw \wedge A\rightarrow v con A,B\in N \wedge w,v\in\Sigma^{*}$
%
%son totalmente equivalentes a las gramáticas regulares normales, pero en muchos casos su notación es mas adecuada.

\section{Análisis sintáctico descendente}

Los métodos descendentes tratan de generar una forma sentencial  a partir del axioma reconstruyendo una  derivación más a la izquierda en orden directo: $S\Rightarrow_{l}^{*}w$. El árbol de derivación se construye desde la raíz hasta las hojas (\textit{análisis LL(k)} o \textit{top-douw})

Un analizador de este tipo está formado por el buffer de entrada, una pila, una tabla de análisis y el programa de control del analizador \textit{(PDA)}.

\imagen{AnalisisSintacticoDescendente}{Estructura del analizador descendente \cite{apuntes}.}


El problema clave durante el análisis sintáctico es determinar la producción que debe aplicarse a un no terminal. 

El analizador sintáctico no recursivo  busca la producción que debe aplicarse en una tabla de análisis sintáctico predictivo $TASP$. A la vista del tope de pila y del símbolo nos dice que acción llevar a cabo.
              
\subsection{Construcción de la \textit{TASP}}

Está compuesta por entradas de la forma $M[a,X]=(X\rightarrow w)$        cuando 
          $a\in FIRST(w.FOLLOW(X))$.
\imagen{Tabla-TASP}{Tabla de análisis sintáctico predictivo \cite{apuntes}.}

 
\subsection{Uso de la \textit{TASP}}

Las acciones del $PDA$ en función de la entrada y de
la pila son:

  Si $X=a=\$$, cadena reconocida y se finaliza el análisis.
  
  Si $X=a\neq \$$, hacemos un pop en la pila y llamamos al analizador léxico para obtener un nuevo token.
  
  Si $X\neq a$, se ha producido un error, llamar a la rutina de recuperación de errores y emitir un mensaje del tipo <<se esperaba un $X$ pero se encontró un $ a $>>.
  
  En cualquier otro caso se consulta la entrada de la tabla $M[a,X]$. Debe aparecer una producción de la forma $ X\rightarrow Y_{1},Y_{2}\ldots  Y_{n}$. Se hace un \textit{pop} de $ X$ y se reemplaza por $Y_{1},Y_{2}\ldots Y_{n}$ con $Y_{1}$ en el tope de la pila.
Si la entrada de tabla está vacía se llama a la rutina de recuperación de error y se emite un mensaje como <<$X$ no puede comenzar por $a$>>.

\subsection{Ejemplo}

\imagen{Ejemplo-TASP}{$TASP$ de la gramática.}


\imagen{Ejemplo-traza}{Traza de la cadena ``tipo begin codigo end $\$$''.}


\subsection{Gramáticas \textit{LL}(1)}

Una gramática cuya \textit{TASP} no tiene entradas múltiples se dice que es \textit{LL}(1).

Si una gramática es \textit{LL}(1) entonces:

\begin{itemize}
\item Es un gramática no ambigua (no existe ninguna cadena a la que se le pueda asociar dos árboles de análisis sintáctico diferentes).
\item Es una gramática no recursiva a izquierdas  (no existe ninguna derivación del tipo $A\Rightarrow^{+}A\alpha$ para un no terminal \textit{A}) 
\item Debe estar factorizada (Para ningún terminal \textit{A} hay dos producciones distintas del tipo $A\longrightarrow\alpha\beta_{1}$, $A\longrightarrow\alpha\beta_{2}$).

\end{itemize}


Se pueden modificar las gramáticas, factorizando por la izquierda o eliminando la recursividad a izquierdas sin modificar el lenguaje que se está reconociendo.



Las gramáticas \textit{LL}(1) permiten construir de forma automática una analizador determinista con tan solo examinar en cada momento el símbolo actual de la cadena de entrada para saber qué producción aplicar. 

%Propiedades de las gramáticas $LL(1)$:
%\begin{enumerate}
%	\item Si $G$ es $LL(1)$, $G$ no es ambigua.
%	\item Si $G$ es $LL(1)$, $G$ no tiene recursividad a izquierda.
%	\item Si $G$ es $LL(1)$, para cada par de producciones $A\rightarrow\alpha$ y $A\rightarrow\beta$ de un no terminal A
%	\begin{itemize}
%		\item Para ningún $a$, $\alpha$   y   $\beta$ derivan cadenas que empiecen por $a$.
%		\item A lo sumo una de $\alpha$   y   $\beta$  derivan la cadena vacía.
%		\item Si $\beta\Rightarrow^{*}\varepsilon$, $\alpha$ no deriva ninguna cadena que comience por $FOLLOW(A)$.
%	\end{itemize}
%	
%\end{enumerate}
	

\section{Análisis sintáctico ascendente}


La idea es generar una forma sentencial a partir del axioma, reconstruyendo una derivación más a la derecha en orden inverso:  $S\Rightarrow_{r}^{*}w$.

Los más utilizados son los  analizadores sintácticos $LR$ que utilizan la técnica de análisis por desplazamiento/reducción. Se parte de la cadena a analizar y se trata de ``reducir"  hasta llegar al símbolo inicial de la gramática.
En cada paso de reducción se sustituye una subcadena determinada que concuerde con el lado derecho de una producción (\textit{asidero}) por el símbolo del lado izquierdo de dicha producción.

Si en cada paso se elige correctamente la cadena, se consigue una derivación por la derecha en sentido inverso.

%El análisis ascendente se basa en la identificación de asideros.
%\begin{itemize}
%	\item Asidero: subcadena de forma sentencial que concuerda con el lado derecho de una producción y cuya reducción al no terminal del lado izquierdo representa un paso a lo largo de la inversa de una derivación por la derecha.
%	\item Prefijo viable: Sea $xhy$ una forma sentencial por la derecha con $h$ un asidero. Se dice que $r$ es un prefijo viable de $xhy$ si $xh=rs$ ($s$ puede ser $\varepsilon$). Es decir, $r$ a lo sumo puede incluir $h$.
%\end{itemize}

Las tres técnicas más comunes para construir tablas de análisis $LR$ son:
\begin{itemize}

\item $SLR$ ($LR simple$): es la más fácil de implementar, pero la menos potente de las tres. Solo son capaces de reconocer un número reducido de gramáticas.

\item $LR$ \textit{canónico}: es la más potente y la más costosa de las tres.

\item $LALR$ ($Lookahead LR$): tiene un costo y una potencia intermedia entre los dos anteriores.

\end{itemize}



Un analizador sintáctico $LR$  consta de un buffer de  entrada, una pila, un programa conductor y una tabla de análisis sintáctico con dos partes, la de \textit{ACCIÓN} y la de \textit{IR A}. 

El programa conductor es el mismo para todos los analizadores sintácticos $LR$, solo cambian la forma de obtener las tablas de un tipo de análisis a otro.

El programa utiliza una pila para almacenar una cadena de la forma $s_{0}X_{1}s_{1}X_{2}s_{2}\ldots X_{m}s_{m} $ donde $s_{m}$ está en la cima. Cada $X_{i}$ es un símbolo gramatical y cada $s_{i}$ es un símbolo llamado estado.

Cada símbolo de estado resume la información contenida debajo de él en la pila, y se usan la combinación del símbolo de estado en la cima de la pila y el símbolo en curso de la entrada para indexar la tabla del análisis sintáctico y determinar la decisión de desplazamiento o reducción del analizador. 

\imagen{Estructuraanalizadorascendente}{Estructura del analizador ascendente}

                
En cada paso hay cuatro opciones:
\begin{itemize}
	\item Poner el token actual en la cima de la pila y llamar al analizador léxico para obtener un nuevo token $(SHIFT)$.
	\item Decidir que los símbolos en la cima de la pila forman un asidero, y entonces desapilarlos y reemplazarlos por la parte izquierda de su producción $(REDUCE)$.
	\item Finalizar aceptando la cadena de entrada.
	\item Finalizar señalando un error.
\end{itemize}

Al realizar análisis ascendente pueden surgir conflictos. Ocurre un conflicto cuando en una entrada de la tabla hay más de una acción. Hay dos tipos de conflicto $SHIFT-REDUCE$ y $REDUCE-REDUCE$ que en algunos casos se pueden resolver mirando el siguiente símbolo de la entrada.

\subsection{Gramáticas  $LR$}

Una gramática para la que se puede construir una tabla de análisis \textit{LR} se dice que es una gramática \textit{LR}. Una gramática que puede ser analizada por un analizador \textit{LR} mirando hasta \textit{k} símbolos de entrada por delante (\textit{lookaheads}) en cada movimiento, se dice que es una gramática $LR(k)$.

\subsection{Análisis $SLR(1)$}

Es la técnica más sencilla que permite un análisis \textit{LR} con previsión de \textit{LookAhead} de un símbolo.

Se basa en la construcción de los conjuntos de items $LR(0)$ de la gramática. Un item $LR(0)$ de una gramática es una de sus producciones, con un punto en algún lugar de su parte derecha. El punto indica hasta donde se ha visto la producción en ese momento del análisis. 
Los ítems se agrupan en estados de un autómata capaz de reconocer asideros en la cima de la pila.
\imagen{ConjuntosLR}{Conjuntos de ítems $LR(0)$.}
Se pueden presentar conflictos \textit{REDUCE-REDUCE}  y \textit{SHIFT-REDUCE} que en algunos casos se pueden resolver. 


\subsection{Análisis $LR(1)$}

Se basa en la  construcción de los items $LR(1)$ de la gramática. Un ítem $LR(1)$ tiene dos componentes: una producción con marca (ítem $LR(0)$) y un conjunto de símbolos de anticipación).  Se aumentan los estados del autómata finito.

\imagen{LR1}{Primeros conjuntos de \textit{ítems LR}(1).}

\imagen{LR2}{Tabla de ACCIÓN  y de IR A en un análisis \textit{LR}(1).}

\imagen{LR3}{Traza de análisis de la cadena ``tipo begin codigo end $\$$''. }


\subsection{Análisis $LALR(1)$}

El análisis $LR(1)$ \textit{canónico} requiere muchos más estados que el análisis $SLR(1)$. Por el contrario hay algunas construcciones de los lenguajes de programación que dan problemas en el análisis $SLR(1)$.

El análisis $LALR(1)$ combina las ventajas de los dos análisis. Puede tratar con las gramáticas problemáticas para el análisis $SLR(1)$, y requiere menos estados que en el análisis $LR(1)$ \textit{canónico}.

Una vez obtenidos los conjuntos $LR(1)$ se identifican aquellos en los que los items del núcleo sólo difieren en los lookahead y se fusionan, haciendo que su lookahead sea la unión.
Sobre el nuevo conjunto de conjuntos de items marcados se aplica el mismo algoritmo de obtención de tablas \textit{ACCIÓN} e \textit{IR A} que para el $LR(1)$ \textit{canónico}.
Pueden surgir conflictos REDUCE/REDUCE que antes no existían. 

%en un conjunto $C$ si
%$ [X\rightarrow \alpha\bullet ,l_{1} ]\in C \wedge [Y\rightarrow\beta\bullet ,l_{2}]\in C \wedge l_{1}\cap  l_{2}\neq\emptyset$.
Si surgen conflictos, la gramática no es $LALR(1)$.

%Se pueden hacer varias modificaciones al algoritmo de obtención de tablas LALR(1) a partir de los conjuntos de items LR(1) para evitar construir la colección completa de conjuntos de elementos LR(1). Para eso hay que darse cuenta de que:
%\begin{enumerate}
%	\item Se puede representar un conjunto I con elementos mediante su núcleo, es decir, mediante aquellos elementos que son el elemento inicial $[S'\rightarrow\bullet S, \$] $ o que tengan el punto en algún lugar que no sea el principio del lado derecho.
%	\item Se pueden calcular las acciones de reducción generadas por I a partir únicamente del núcleo. Cualquier elemento que pida una reducción por $A\rightarrow\alpha$ estará en el núcleo, a menos que $\alpha=\varepsilon$. Se pide la reducción por $A\rightarrow\varepsilon$ si, y sólo si, existe un elemento del núcleo $[B\rightarrow\gamma\bullet C\delta, b]$ tal que $C\Rightarrow_{md}*A\eta$ para alguna$ \eta$, y \textit{a} están en $FIRST(\eta \delta b)$. Se puede precalcular el conjunto de no terminales $A$ tales que $C\Rightarrow_{md}*A\eta $para cada no terminal $C$ (en general $FIRST(\eta b\delta b)\neq FOLLOW(A)$, aunque
%$FIRST(\eta b\delta b)\subseteq FOLLOW(A))$.
%	\item Se pueden determinar las acciones de desplazamiento generadas por I a partir únicamente del núcleo. Se hace un desplazamiento con la entrada a si hay un elemento del núcleo $[B\rightarrow\gamma\bullet C\delta, b]$, donde $C\Rightarrow_{md} *ax$ en una derivación en que el último paso no utiliza una producción $\varepsilon$. También se puede precalcular el conjunto de dichas a para cada $C$.
%	\item Se pueden calcular las transiciones $\text{ir\_a}$ para $I$ a partir del núcleo. Si $[B\rightarrow\gamma\bullet X\delta,b]$ está en el núcleo de $I$, entonces $[B\rightarrow\gamma X\bullet \delta,b]$ está en el núcleo de $\text{ir\_a}(I,X)$. El elemento $[A\rightarrow X\bullet \beta,a]$ está también en el núcleo de $\text{ir\_a}(I,X)$ si hay un elemento $[B\rightarrow\gamma\bullet C\delta,b]$ en el núcleo de $I$, y $C\Rightarrow_{md}*A\eta$ para alguna$\eta$. Si para cada par de no terminales $C$ y $A$ se precalcula si $C\Rightarrow_{md} *A\eta$ para alguna $\eta$, entonces calcular los conjuntos de elementos a partir de los núcleos sólo es un poco menos eficiente que hacerlo con conjuntos cerrados de elementos.
%\end{enumerate}






















